{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import math\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (test_x, test_y) = cifar10.load_data()\n",
    "\n",
    "num_classes = 10\n",
    "train_y_cls = np_utils.to_categorical(y_train,num_classes)\n",
    "test_y_cls = np_utils.to_categorical(test_y,num_classes)\n",
    "\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(x_train)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "class_names = load_label_names()\n",
    "\n",
    "def label_to_array(cls_true):\n",
    "    true = cls_true.tolist()\n",
    "    true_label = []\n",
    "    for l in true:\n",
    "        true_label += l\n",
    "    return true_label\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Random Validation and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_size = x_train.shape[0]\n",
    "split_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper-function for splitting the combined data-set into a random training- and validation-set.\n",
    "\n",
    "def random_training_set(split_size):\n",
    "    \n",
    "    train_size = int(combined_size*(1-split_size))\n",
    "\n",
    "    # Create a randomized index into the full / combined training-set.\n",
    "    idx = np.random.permutation(combined_size)\n",
    "\n",
    "    # Split the random index into training- and validation-sets.\n",
    "    idx_train = idx[0:train_size]\n",
    "    idx_validation = idx[train_size:]\n",
    "\n",
    "    # Select the images and labels for the new training-set.\n",
    "    train = x_train[idx_train, :]\n",
    "    labels = y_train[idx_train, :]\n",
    "\n",
    "    # Select the images and labels for the new validation-set.\n",
    "    x_validation = x_train[idx_validation, :]\n",
    "    y_validation = y_train[idx_validation, :]\n",
    "\n",
    "    # Return the new training- and validation-sets.\n",
    "    return train, labels, x_validation, y_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into random training and validation data\n",
    "train_x, train_y, validation_x, validation_y = random_training_set(split_size)\n",
    "\n",
    "train_y_cls = np_utils.to_categorical(train_y,num_classes)\n",
    "validation_y_cls = np_utils.to_categorical(validation_y,num_classes)\n",
    "\n",
    "print (train_x.shape)\n",
    "print (validation_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Dimensions\n",
    "\n",
    "# CIFAR-10 images are 32 pixels in each dimension.\n",
    "img_size = 32\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images:\n",
    "num_channels = 3\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10\n",
    "\n",
    "input_shape = (img_size, img_size, num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Images\n",
    "\n",
    "def plot_images(images, cls_true, cls_pred=None, smooth=True):\n",
    "\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    # Adjust vertical spacing if we need to print ensemble and best-net.\n",
    "    if cls_pred is None:\n",
    "        hspace = 0.3\n",
    "    else:\n",
    "        hspace = 0.6\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Interpolation type.\n",
    "        if smooth:\n",
    "            interpolation = 'spline16'\n",
    "        else:\n",
    "            interpolation = 'nearest'\n",
    "\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i, :, :, :],\n",
    "                  interpolation=interpolation)\n",
    "            \n",
    "        # Name of the true class.\n",
    "        cls_true_name = class_names[cls_true[i]]\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true_name)\n",
    "        else:\n",
    "            # Name of the predicted class.\n",
    "            cls_pred_name = class_names[cls_pred[i]]\n",
    "\n",
    "            xlabel = \"True: {0}\\nPred: {1}\".format(cls_true_name, cls_pred_name)\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing Data\n",
    "def data_prep(train, validation,test, subtract_pixel_mean):\n",
    "    # Normalize Data\n",
    "    train = train.astype('float32')/255\n",
    "    validation = validation.astype('float32')/255\n",
    "    test = test.astype('float32')/255\n",
    "    \n",
    "    # If subtract pixel mean is enabled\n",
    "    if subtract_pixel_mean:\n",
    "        train_mean = np.mean(train, axis=0)\n",
    "        train -= train_mean\n",
    "        validation -= train_mean\n",
    "        test -= train_mean\n",
    "        \n",
    "    return train, validation, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract per pixel\n",
    "subtract_pixel_mean = True\n",
    "\n",
    "train_x, validation_x, test_x = data_prep(train_x, validation_x, test_x, subtract_pixel_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def augment_batches(batch_size, data):\n",
    "    '''\n",
    "    Return a total of `num` samples\n",
    "    '''\n",
    "    \n",
    "    images=batch_size\n",
    "    while(images + batch_size <= len(data)):\n",
    "        prev_no = images\n",
    "        images += batch_size\n",
    "        data[prev_no:images] = crop_images(data[prev_no:images])\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# Padding images to 36x36 then randomly crop 32x32 size images\n",
    "def crop_images(train):\n",
    "    \n",
    "    # Zero pad images to 36x36 size\n",
    "    train = tf.image.resize_with_crop_or_pad(train,\n",
    "                                             target_height=36,\n",
    "                                             target_width=36).numpy()\n",
    "    train = tf.image.random_crop(train, size=[train.shape[0], 32, 32, 3])\n",
    "    \n",
    "    return train.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose if images should be randomly cropped\n",
    "crop_images = False\n",
    "\n",
    "if (crop_images):\n",
    "    train_x = augment_batches(train_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first 9 images from the test-set.\n",
    "images = train_x[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = train_y[0:9]\n",
    "cls_true = label_to_array(cls_true)\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images, cls_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Add\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an Inception Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_module(net, filters, shape, stage, block):\n",
    "    '''\n",
    "    Arguments: \n",
    "    1. net -- input tensor of shape(m, h_prev, w_prev, c_prev)\n",
    "    2. shape -- integer, specifying the shape of the middle CONV's\n",
    "    window for the main path\n",
    "    3. filters -- list of integers, defining the no of filters of \n",
    "    CONV layers in the main path\n",
    "    4. stage -- integer, used to name the layers depending on their \n",
    "    position in the network\n",
    "    5. block -- string/character used to name the layers depending\n",
    "    on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    net -- output of the identity block, tensor of shape\n",
    "    (h_curr, w_curr, c_curr)\n",
    "    '''\n",
    "    \n",
    "    # Defining name basis\n",
    "    conv_name_base = 'res' + stage + block \n",
    "    bn_name_base = 'bn' + stage + block \n",
    "    \n",
    "    # Conv component\n",
    "    net = Conv2D(filters=filters, kernel_size=(shape,shape),\n",
    "                 name = conv_name_base ,\n",
    "                 strides=(1,1), padding='same')(net)\n",
    "    net = BatchNormalization(axis = 3, name = bn_name_base)(net)\n",
    "    net = Activation('relu')(net)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(net, \n",
    "                     filter1x1,\n",
    "                     filter3x3_reduce,\n",
    "                     filter3x3,\n",
    "                     filter5x5_reduce,\n",
    "                     filter5x5v1,\n",
    "                     filter5x5v2,\n",
    "                     filterpool,\n",
    "                     stage):\n",
    "        \n",
    "    # 1x1 branch\n",
    "    net_1x1 = conv_module(net, filter1x1, shape=1, stage=stage, block='1x1')\n",
    "    \n",
    "    # 3x3 branch\n",
    "    net_3x3 = conv_module(net, filter3x3_reduce, shape=1, stage=stage, block='3x3_downsample')\n",
    "    net_3x3 = conv_module(net_3x3, filter3x3, shape=3, stage=stage, block='3x3')\n",
    "    \n",
    "    # 5x5 branch (use 2 3x3 conv)\n",
    "    net_3x3v1 = conv_module(net, filter5x5_reduce, shape=1, stage=stage, block='5x5_downsample')\n",
    "    net_3x3v1 = conv_module(net_3x3v1, filter5x5v1, shape=3, stage=stage, block='3x3v1')\n",
    "    net_3x3v2 = conv_module(net_3x3v1, filter5x5v2, shape=3, stage=stage, block='3x3v2')\n",
    "    \n",
    "    # MaxPool branch\n",
    "    net_pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(net)\n",
    "    net_pool = conv_module(net_pool, filterpool, shape=1, stage=stage, block='pool')\n",
    "    \n",
    "    # Concatinate all branches together\n",
    "    net = concatenate([net_3x3, net_3x3v2, net_1x1, net_pool],\n",
    "                     axis=3, name='inception'+stage )\n",
    "    \n",
    "    return net\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Implementation of the ImageNet having the following architecture:\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define a tensor with input shape\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Stage 1 --> 3x3 Convolution with 16 filters and stride 1\n",
    "    net = Conv2D(32, (3,3), strides=(1,1), padding='same',\n",
    "                name='conv1')(inputs)\n",
    "    net = BatchNormalization(axis=3, name='bn_conv1')(net)\n",
    "    net = Activation('relu')(net)\n",
    "    \n",
    "    # No of inception_modules \n",
    "    # Assume 6 modules (loss after each 2 modules)\n",
    "    \n",
    "    net = inception_module(net, \n",
    "                           filter1x1=32,\n",
    "                           filter3x3_reduce=24,\n",
    "                           filter3x3=32,\n",
    "                           filter5x5_reduce=8,\n",
    "                           filter5x5v1=16,\n",
    "                           filter5x5v2=16,\n",
    "                           filterpool=16,\n",
    "                           stage='1a')\n",
    "    \n",
    "    # Loss after first inception module\n",
    "    loss1 = AveragePooling2D((3,3),strides=(2,2),name='loss1')(net)\n",
    "    loss1 = Conv2D(16,(1,1), padding='same',\n",
    "                        activation='relu',\n",
    "                        name='loss1-conv')(loss1)\n",
    "    loss1 = Flatten()(loss1)\n",
    "    loss1 = Dense(32,activation='relu',name='loss1-fc')(loss1)\n",
    "    loss1 = Dropout(0.5)(loss1)\n",
    "    loss1 = Dense(num_classes, name='loss1-classifier',)(loss1)\n",
    "    loss1 = Activation('softmax')(loss1)\n",
    "    \n",
    "    # Continue the NN\n",
    "    net = inception_module(net, \n",
    "                           filter1x1=20,\n",
    "                           filter3x3_reduce=16,\n",
    "                           filter3x3=32,\n",
    "                           filter5x5_reduce=12,\n",
    "                           filter5x5v1=16,\n",
    "                           filter5x5v2=16,\n",
    "                           filterpool=16,\n",
    "                           stage='2a')\n",
    "    \n",
    "    # Loss after 2nd inception module\n",
    "    loss2 = AveragePooling2D((3,3),strides=(2,2),name='loss2')(net)\n",
    "    loss2 = Conv2D(16,(1,1), padding='same',\n",
    "                        activation='relu',\n",
    "                        name='loss2-conv')(loss2)\n",
    "    loss2 = Flatten()(loss2)\n",
    "    loss2 = Dense(32,activation='relu',name='loss2-fc')(loss2)\n",
    "    loss2 = Dropout(0.5)(loss2)\n",
    "    loss2 = Dense(num_classes, name='loss2-classifier')(loss2)\n",
    "    loss2 = Activation('softmax')(loss2)\n",
    "    \n",
    "    # Continue the NN\n",
    "    net = inception_module(net, \n",
    "                           filter1x1=32,\n",
    "                           filter3x3_reduce=20,\n",
    "                           filter3x3=32,\n",
    "                           filter5x5_reduce=16,\n",
    "                           filter5x5v1=32,\n",
    "                           filter5x5v2=32,\n",
    "                           filterpool=32,\n",
    "                           stage='3a')\n",
    "    \n",
    "    # Loss of final module\n",
    "    loss3 = AveragePooling2D((3, 3), strides=(2,2))(net)\n",
    "    loss3 = Flatten()(loss3)\n",
    "    loss3 = Dense(128, name='loss3_dense')(loss3)\n",
    "    loss3 = Activation('relu')(loss3)\n",
    "    loss3 = Dropout(0.4)(loss3)\n",
    "    loss3 = Dense(num_classes, name='loss3-classifier')(loss3)\n",
    "    loss3 = Activation(\"softmax\")(loss3)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[loss1,loss2,loss3], name='Inception')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Model\n",
    "model = inception(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "# Initialize the optimizer and compile the model\n",
    "optimizer = SGD(lr=0.0, momentum=0.9, decay=0.0001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Decay\n",
    "By using step decay, we schedule drop the learning rate by a factor every few epochs.\n",
    "\n",
    "#### Is useful when training for long epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define step decay function\n",
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.lr = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.lr.append(step_decay(len(self.losses)))\n",
    "        print('lr:', step_decay(len(self.losses)))\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.1\n",
    "    epochs_drop = num_epochs/2\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "# learning schedule callback\n",
    "loss_history = LossHistory()\n",
    "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "callbacks_list = [loss_history, lrate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    h = model.fit(train_x,\n",
    "                  [train_y_cls,train_y_cls,train_y_cls],\n",
    "                  batch_size = 128,\n",
    "                  validation_data=(validation_x,\n",
    "                                   [validation_y_cls,validation_y_cls,validation_y_cls]),\n",
    "                  callbacks=callbacks_list, \n",
    "                  epochs = num_epochs,\n",
    "                  verbose = 1)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_x)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(train_x, [train_y_cls,train_y_cls,train_y_cls],\n",
    "                                     batch_size=128),\n",
    "                                     validation_data=(validation_x, \n",
    "                                                     [validation_y_cls,validation_y_cls,validation_y_cls]),\n",
    "                                     epochs=num_epochs, verbose=1, workers=4,\n",
    "                                     callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(test_x, test_y_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on test_set\n",
    "pred_y = model.predict(test_x)\n",
    "pred_cls = np.argmax(pred_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some predicted Images\n",
    "# Get the first 9 images from the test-set.\n",
    "images = test_x[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = test_y[0:9]\n",
    "cls_true = label_to_array(cls_true)\n",
    "\n",
    "#Get Predicted Classes\n",
    "cls_pred = pred_cls[0:9]\n",
    "cls_pred = cls_pred.tolist()\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images, cls_true, cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
