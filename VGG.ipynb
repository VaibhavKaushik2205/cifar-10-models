{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import math\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (test_x, test_y) = cifar10.load_data()\n",
    "\n",
    "num_classes = 10\n",
    "y_train_cls = np_utils.to_categorical(y_train,num_classes)\n",
    "test_y_cls = np_utils.to_categorical(test_y,num_classes)\n",
    "\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(x_train)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "class_names = load_label_names()\n",
    "\n",
    "def label_to_array(cls_true):\n",
    "    true = cls_true.tolist()\n",
    "    true_label = []\n",
    "    for l in true:\n",
    "        true_label += l\n",
    "    return true_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Dimensions\n",
    "\n",
    "# CIFAR-10 images are 32 pixels in each dimension.\n",
    "img_size = 32\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images:\n",
    "num_channels = 3\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Images\n",
    "\n",
    "def plot_images(images, cls_true, cls_pred=None, smooth=True):\n",
    "\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    # Adjust vertical spacing if we need to print ensemble and best-net.\n",
    "    if cls_pred is None:\n",
    "        hspace = 0.3\n",
    "    else:\n",
    "        hspace = 0.6\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Interpolation type.\n",
    "        if smooth:\n",
    "            interpolation = 'spline16'\n",
    "        else:\n",
    "            interpolation = 'nearest'\n",
    "\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i, :, :, :],\n",
    "                  interpolation=interpolation)\n",
    "            \n",
    "        # Name of the true class.\n",
    "        cls_true_name = class_names[cls_true[i]]\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true_name)\n",
    "        else:\n",
    "            # Name of the predicted class.\n",
    "            cls_pred_name = class_names[cls_pred[i]]\n",
    "\n",
    "            xlabel = \"True: {0}\\nPred: {1}\".format(cls_true_name, cls_pred_name)\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first 9 images from the test-set.\n",
    "images = x_train[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = y_train[0:9]\n",
    "cls_true = label_to_array(cls_true)\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images, cls_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise Data\n",
    "x_train = (x_train.astype('float32'))/255.\n",
    "test_x = (test_x.astype('float32'))/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_x, validation_x, train_y, validation_y = train_test_split(x_train, y_train_cls,\n",
    "                                                                test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(width, height, channels, architecture, classes):\n",
    "    # Initialize the model along with the input shape to be\n",
    "    # \"channels last\" ordering\n",
    "    # Here, we are taking the size of all filters as 3x3 and adding BatchNormalisation after each layer\n",
    "    # Architecture -- list telling architecture of VGG model (eg. for VGG11->[64,M,128,M,256,256,M,512,512,M])\n",
    "    \n",
    "    inputShape = (height, width, channels)\n",
    "    \n",
    "    inputs = Input(inputShape)\n",
    "    net = inputs\n",
    "    \n",
    "    for i in (architecture):\n",
    "        if i=='M':\n",
    "            net = MaxPooling2D(pool_size = 2, strides = 2,\n",
    "                          padding=\"same\")(net)\n",
    "        else:\n",
    "            net = Conv2D(filters=i, kernel_size=(3,3),\n",
    "                         dtype=tf.float32, strides=1,\n",
    "                         padding='same')(net)\n",
    "            net = Activation(\"relu\")(net)\n",
    "            net = BatchNormalization()(net)\n",
    "        \n",
    "    # Flatten\n",
    "    net = Flatten()(net)\n",
    "    \n",
    "    # First Dense Layer with ReLU activation\n",
    "    net = Dense(512)(net)\n",
    "    net = Activation(\"relu\")(net)\n",
    "    net = Dropout(0.4)(net)\n",
    "\n",
    "    # Final Dense Layer with softmax activation\n",
    "    net = Dense(num_classes)(net)\n",
    "    net = Activation(\"softmax\")(net)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=net, name='VGG')\n",
    "    # return the constructed network architecture\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG Models\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Model\n",
    "model = vgg(32, 32, 3, cfg['VGG11'], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "# Initialize the optimizer and compile the model\n",
    "optimizer = Adam(lr=0.1, decay=0.0005 / num_epochs)\n",
    "print(\"Training network...\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmnetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Data Augmentation or not\n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training, with or without data augmentation.\n",
    "if not augment_data:\n",
    "    print('Not using data augmentation.')\n",
    "    h = model.fit(train_x,\n",
    "                  train_y,\n",
    "                  batch_size = 128,\n",
    "                  validation_data=(validation_x,validation_y),\n",
    "                  epochs = num_epochs,\n",
    "                  verbose = 1)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        fill_mode='nearest',\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(train_x,train_y, batch_size=128),\n",
    "                        epochs=num_epochs, verbose=1, workers=4, \n",
    "                        validation_data=(validation_x,validation_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on Test Set\n",
    "result = model.evaluate(test_x, test_y_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on test_set\n",
    "pred_y = model.predict(test_x)\n",
    "pred_cls = np.argmax(pred_y, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some predicted Images\n",
    "# Get the first 9 images from the test-set.\n",
    "images = test_x[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = test_y[0:9]\n",
    "cls_true = label_to_array(cls_true)\n",
    "\n",
    "#Get Predicted Classes\n",
    "cls_pred = pred_cls[0:9]\n",
    "cls_pred = cls_pred.tolist()\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images, cls_true, cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
